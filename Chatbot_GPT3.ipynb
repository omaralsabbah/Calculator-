{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omaralsabbah/Python-/blob/main/Chatbot_GPT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuW4YNha58e2"
      },
      "source": [
        "install openai library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjg-Wa9XHNQr",
        "outputId": "c2442e5f-98db-4c11-f1ff-8c3696aa7e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.4.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.4-py3-none-any.whl size=67744 sha256=21d588f5f7092776506c9d9b164a3af2fbb2742f57b3eddfbcc4f4b327947b93\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/d8/4e/268f029bd3277c1dd9e8781a0e0296e0a63822665bfa2429fc\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tllsCf66CAs"
      },
      "source": [
        "Preparing the data used to train the model in the required format using ' prepare_data' method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmeCGOmlHP_P",
        "outputId": "dba83aa2-3a1b-4a08-8c65-080b0c701369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 37 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `/content/intents_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/intents_prepared.jsonl\"\n",
            "\n",
            "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.95 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f /content/intents.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aktP0MK36hDY"
      },
      "source": [
        "Saving the API key obtained from OpenAI account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAavC8HRHRAm"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "os.environ['OPENAI_API_KEY'] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPJDzkXM7Clu"
      },
      "source": [
        "Model fine-tuning using the prepared data of customer interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MpGYUnjHRIF",
        "outputId": "56f17d8d-3449-48d4-decd-d60d049b2ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rUpload progress:   0% 0.00/9.99k [00:00<?, ?it/s]\rUpload progress: 100% 9.99k/9.99k [00:00<00:00, 12.9Mit/s]\n",
            "Uploaded file from /content/intents_prepared.jsonl: file-9c2xGFCGgeaLsdHaFeunNFW9\n",
            "Created fine-tune: ft-02M6ZC7F6v2ZLvkdieZXIifn\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-01-29 14:03:44] Created fine-tune: ft-02M6ZC7F6v2ZLvkdieZXIifn\n",
            "[2023-01-29 14:04:47] Fine-tune costs $0.23\n",
            "[2023-01-29 14:04:47] Fine-tune enqueued. Queue number: 0\n",
            "[2023-01-29 14:04:49] Fine-tune started\n",
            "[2023-01-29 14:06:31] Completed epoch 1/4\n",
            "[2023-01-29 14:06:42] Completed epoch 2/4\n",
            "[2023-01-29 14:06:54] Completed epoch 3/4\n",
            "[2023-01-29 14:07:06] Completed epoch 4/4\n",
            "[2023-01-29 14:07:53] Uploaded model: davinci:ft-personal-2023-01-29-14-07-49\n",
            "[2023-01-29 14:07:54] Uploaded result file: file-btHyBh3gXZGmCwDwCrsdbYsD\n",
            "[2023-01-29 14:07:55] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-personal-2023-01-29-14-07-49 -p <YOUR_PROMPT>\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.create -t /content/intents_prepared.jsonl -m 'davinci'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX-sklUmHRK1"
      },
      "outputs": [],
      "source": [
        "#prompt= 'I think that this month\\'s bill is very high, I didn\\'t expect that ->'\n",
        "#prompt= 'why is the coverage very bad? ->'\n",
        "#prompt='how can I cancel all the promotional sms services? ->'\n",
        "#prompt='how can I cancel the promotional sms services? ->'\n",
        "prompt='hello, can you provide me with a better subscription plan?  ->'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90m-ZR4J7Vft"
      },
      "source": [
        "import OpenAI library , and use the tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYFjEcLjHRNo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"davinci:ft-personal-2023-01-29-14-07-49\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.7,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzb3o2AV7n9Z"
      },
      "source": [
        "CHATBOT Prompt and answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8grwhStHRQC",
        "outputId": "c1e1935a-00f0-49e8-d305-fbafb93c3015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your message [ or exit if done ]:how can I cancel the promotional sms services?\n",
            " please provide me with your mobile number and I will assist you with the process of cancelling the promotional sms services.\n",
            "Enter your message [ or exit if done ]:I think that this month's bill is very high, I didn't expect that\n",
            " I apologize for the high bill. Can you please run me through your usage so I can investigate the charges? We value your loyalty and I'd like to resolve this issue for you.\n",
            "Enter your message [ or exit if done ]:exit\n"
          ]
        }
      ],
      "source": [
        "asking=True\n",
        "\n",
        "while asking==True:\n",
        "  prompt=input('Enter your message [ or exit if done ]:')+'->'\n",
        "  if prompt == 'exit->':\n",
        "    asking = False\n",
        "  else:\n",
        "    response = openai.Completion.create(\n",
        "  model=\"davinci:ft-personal-2023-01-29-14-07-49\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.7,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        "  )\n",
        "    print(response[\"choices\"][0][\"text\"])\n",
        "\n",
        "  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIir9mrkSG7JAg+008/KhN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}